macPoints <- data.frame(lat = c(9.894261, 9.885805, 9.892569, 9.9009440, 9.892992),
lng = c(-84.081528, -84.06976, -84.064019, -84.068224, -84.080241));
my_map <- macdonadls %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = macIcon, popup = macInfo)
my_map
macPoints <- data.frame(lat = c(9.894261, 9.885805, 9.892485, 9.9009440, 9.892992),
lng = c(-84.081528, -84.06976, -84.063160, -84.068224, -84.080241));
my_map <- macdonadls %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = macIcon, popup = macInfo)
my_map
my_map <- macPoints %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = macIcon, popup = macInfo)
my_map
ibrary(leaflet)
ibrary(leaflet)
library(leaflet)
macInfo <- c(
"McDonal's",
"McDonal's",
"McDonal's",
"McDonal's",
"McDonal's"
)
macIcon <- makeIcon(
iconUrl = "https://img.utdstc.com/icons/mcdonalds-usa-llc-mcdonald-android.png:l",
iconWidth =  31*215/230 ,iconHeight = 31,
iconAnchorX = 3*215/230/2, iconAnchorY = 16
)
macPoints <- data.frame(lat = c(9.894261, 9.885805, 9.892485, 9.9009440, 9.892992),
lng = c(-84.081528, -84.06976, -84.063160, -84.068224, -84.080241));
my_map <- macPoints %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = macIcon, popup = macInfo)
my_map
install.packages("plotly")
library(plotly)
plot_ly(mtcars, x = ~wt, y = ~mpg, type = "scatter")
plot_ly(mtcars, x = ~wt, y = ~mpg, type = "scatter", color = ~disp)
Source_Classification_Code <- readRDS("~/Coursera/Data Science/Exploratory data analysis/Source_Classification_Code.rds")
plot_ly(mtcars, y = ~mpg, color = ~am, type = "box")
plot_ly(mtcars, x= ~am, y = ~mpg, type = "box")
plot_ly(mtcars, x= ~am, y = ~mpg, type = "box") %>%
add_trace(y = ~mpg)
plot_ly(mtcars, x= ~am, y = ~mpg, color = ~am, type = "box")
plot_ly(mtcars, y = ~mpg, color = ~am, type = "box")
plot_ly(mtcars, y = ~mpg, color = ~am, type = "box", boxpoints = "all"
)
plot_ly(mtcars, y = ~mpg, x = ~am, type = "box", boxpoints = "all")
plot_ly(mtcars, y = ~mpg, x = ~factor(am), type = "box", boxpoints = "all")
plot_ly(mtcars, y = ~mpg, color = ~factor(am), type = "box", boxpoints = "all")
ddd <- mtcars$am==1
?mtcars
library(ggplot2)
library(plotly)
data(mtcars)
plot_ly(mtcars, y = ~mpg, color = ~factor(am), type = "box", boxpoints = "all")
```{r plot, echo=FALSE}
library(ggplot2)
library(plotly)
data(mtcars)
plot_ly(mtcars, y = ~mpg, color = ~factor(am), type = "box", boxpoints = "all")
clr
clear
library(ggplot2)
library(plotly)
data(mtcars)
plot_ly(mtcars, y = ~mpg, color = ~as.factor(am), type = "box", boxpoints = "all")
plot_ly(mtcars, y = ~mpg, color = ~am, type = "box", boxpoints = "all")
mtcars$am <- as.factor(am)
mtcars$am <- as.factor(mtcars$am)
plot_ly(mtcars, y = ~mpg, color = ~am, type = "box", boxpoints = "all")
plot_ly(mtcars, color = am, y = mpg, color = am, type = "box", boxpoints = "all")
plot_ly(mtcars, color = am, y = mpg, color = am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, color = ~am, y = ~mpg, color = ~am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, colors = c("#132B43", "#56B1F7"), type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, colors = ~am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, colors = c("#132B43", "#56B1F7"),type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, colors = c("#b2e0d2", "#c6cfe5"), type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
library(shiny)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
library(ggplot2)
library(plotly)
data(mtcars)
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, colors = c("#b2e0d2", "#c6cfe5"), type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
head(mtcars,)
p <- plot_ly(data = mtcars, x = ~mpg, y = ~cyl)
p
p <- plot_ly(data = mtcars, x = ~mpg, y = ~cyl, color = ~wt)
p
p <- plot_ly(data = mtcars, x = ~mpg, y = ~wt, color = ~cyl)
p
plot_ly(mtcars, x = ~am, y = ~mpg, color = ~am, colors = c("#b2e0d2", "#c6cfe5"), type = "box", boxpoints = "all", jitter = 0.4,pointpos = -1.8)
p <- plot_ly(data = mtcars, x = ~mpg, y = ~wt, color = ~disp, type = "scatter")
p
x <- mtcars$mpg
y <- mtcars$wt
color <- mtcars$cyl
p <- plot_ly(x = ~x, y = ~y, color = ~color, type = "scatter")
p
plot_ly(x = ~x, y = ~y, color = ~color, type = "scatter", mode = "markers")
sss <- mtcars$mpg[mtcars$wt>3]
dim(mtcars)
sss <- mtcars$mpg[mtcars$mpg>3]
sss <- mtcars$wt[mtcars$wt>3]
sss <-[mtcars$wt>3
sss <-[tcars$wt>3
sss <-mtcars$wt>3
View(mtcars)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
summary(mtcars$wt)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
sss <- mtcars$wt>=3 && mtcars$wt<=4
shiny::runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
library(shiny)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
shiny::runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
library(ggplot2)
library(plotly)
data(mtcars)
head(mtcars)
?mtcars
summary(mtcars$cyl)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
wtFilter <- mtcars$wt>=3 && mtcars$wt<=4
cyl <- mtcars$cyl >=3 && mtcars$cyl 6
wtFilter <- mtcars$wt>=3 && mtcars$wt<=4
cylFilter <- mtcars$cyl >=3 && mtcars$cyl<=6
data <- mtcars[wtFilter && cylFilter]
wtFilter <- mtcars$wt>=3 && mtcars$wt<=4
cylFilter <- mtcars$cyl >=3 && mtcars$cyl<=6
data <- mtcars[wtFilter && cylFilter,]
wtFilter <- mtcars$wt>=3 && mtcars$wt<=4
cylFilter <- mtcars$cyl >=3 && mtcars$cyl<=6
wtFilter <- mtcars$wt>=3
wtFilter <- (mtcars$wt>=3 && mtcars$wt<=4)
cylFilter <- (mtcars$cyl >=3 && mtcars$cyl<=6)
cylFilter <- mtcars$cyl >=3
wtFilter <- (mtcars$wt>=3) && (mtcars$wt<=4)
View(data)
wtFilter <- mtcars[,mtcars$wt>=3 && (mtcars$wt<=4]
wtFilter <- mtcars[,mtcars$wt>=3 && mtcars$wt<=4]
wtFilter <- mtcars[mtcars$wt>=3 && mtcars$wt<=4,]
View(mtcars)
wtFilter <- mtcars[mtcars$wt>2 && mtcars$wt<=4,]
View(wtFilter)
wtFilter <- mtcars[mtcars$wt>2,]
data <- mtcars %>% filter(wt %in% (2:5))
View(data)
View(mtcars)
data <- mtcars %>% filter(wt %in% (0:8))
filter(mtcars,wt %in% (0:8))
filter(mtcars,wt > 0))
filter(mtcars,wt > 0)
filter(mtcars,wt > 2)
filter(mtcars, wt %between% c(0,1))
class(mtcars)
cylFilter <- mtcars$cyl >=3 & mtcars$cyl<=6
wtFilter <- mtcars$wt >= 2 & mtcars$wt <= 4
cylFilter <- mtcars$cyl >=3 & mtcars$cyl<=6
data <- mtcars[wtFilter,]
data <- mtcars[wtFilter & cylFilter,]
x <- data$mpg
y <- data$wt
color <- data$cyl
plot_ly(x = ~x, y = ~y, color = ~color, type = "scatter", mode = "markers")
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
plot(x,y, type = "scatter")
?plot
plot(y,x)
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
runApp('~/Coursera/Data Science/Developing Data Prodct/Sniny_App/Developing_Data_Products')
library(NLP)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
library(ggplot2)
library(plotly)
setwd("~/Coursera/Data Science/Data Science Capstone")
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con,5000)
close(con)
library(ggplot2)
library(plotly)
library(NLP)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
library(ggplot2)
library(plotly)
library(NLP)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
setwd("~/Coursera/Data Science/Data Science Capstone")
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con,5000)
close(con)
?rbinom
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.5)
twitterText <- twitterText[as.logical(index)]
length(textTwitter)
cntTwitter <- sapply(textTwitter, nchar)
length(twitterText)
summary(twitterText)
twitterLng <- length(twitterText)
twitterCnt <- sapply(textTwitter, nchar)
twitterLng <- length(twitterText)
twitterCnt <- sapply(twitterText, nchar)
twittweLongest <- max(TwitterCnt)
twittweLongest <- max(twitterCnt)
dataFacts <- data.frame("Size" = twitterLng, "Longest line" = twittweLongest)
dataFacts
row.names(dataFacts) <- c("Twitter")
dataFacts
dataFacts <- data.frame("#_of_lines" = twitterLng, "Longest_line" = twittweLongest)
row.names(dataFacts) <- c("Twitter")
dataFacts
twitterText$size
con <- file("en_US.twitter.txt", "r")
con$size
twitterText <- readLines(con,5000)
close(con)
file.info("en_US.twitter.txt")$size
file.info("~/en_US.twitter.txt")$size
file.info("~/en_US.twitter.txt")
file.info("en_US.twitter.txt")
setwd("~/Coursera/Data Science/Data Science Capstone")
file.info("en_US.twitter.txt")
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.5)
twitterText <- twitterText[as.logical(index)]
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity)))
twitCorpus <- VCorpus(VectorSource(twitText_clean))
twitCorpus_clean <- tm_map(twitCorpus,removeNumbers) #removing numbers
twitCorpus_clean <- tm_map(twitCorpus_clean,content_transformer(tolower)) #converting to lower case letters
twitCorpus_clean <- tm_map(twitCorpus_clean,removePunctuation) #remving punctuation
twitCorpus_clean <- tm_map(twitCorpus_clean,stripWhitespace)
library(ggplot2)
library(plotly)
library(NLP)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
setwd("~/Coursera/Data Science/Data Science Capstone")
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con,5000)
close(con)
twitterLng <- length(twitterText)
twitterCnt <- sapply(twitterText, nchar)
twittweLongest <- max(twitterCnt)
dataFacts <- data.frame("Length" = twitterLng, "Longest_line" = twittweLongest)
row.names(dataFacts) <- c("Twitter")
dataFacts
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.5)
twitterText <- twitterText[as.logical(index)]
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity))) # Profanity filter
twitCorpus <- VCorpus(VectorSource(twitText_clean))
twitCorpus_clean <- tm_map(twitCorpus,removeNumbers) #removing numbers
twitCorpus_clean <- tm_map(twitCorpus_clean,content_transformer(tolower)) #converting to lower case letters
twitCorpus_clean <- tm_map(twitCorpus_clean,removePunctuation) #remving punctuation
twitCorpus_clean <- tm_map(twitCorpus_clean,stripWhitespace)
twit_tdm <- TermDocumentMatrix(twitCorpus_clean) #Tokenization
word_matrix <- sort(rowSums(as.matrix(twit_tdm)),decreasing=TRUE) #Order the the words
wordFreq <- data.frame(word = names(word_matrix),freq=word_matrix)
rownames(wordFreq) <- NULL
head(wordFreq,10) #Top 10 of frecuent word
plot_ly(x = ~wordFreq$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq$word, wordFreq$freq, max.words=500, min.freq = 2, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 2, colors=brewer.pal(8, "Dark2")) #Wordcloud
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con)
close(con)
>readLines()
?readLines(
)
twitterLng <- length(twitterText)
twitterCnt <- sapply(twitterText, nchar)
twittweLongest <- max(twitterCnt)
dataFacts <- data.frame("Length" = twitterLng, "Longest_line" = twittweLongest)
row.names(dataFacts) <- c("Twitter")
dataFacts
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.5)
twitterText <- twitterText[as.logical(index)]
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity))) # Profanity filter
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.1)
twitterText <- twitterText[as.logical(index)]
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity))) # Profanity filter
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con)
close(con)
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con, skipNul=T)
close(con)
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.01)
twitterText <- twitterText[as.logical(index)]
twitterLng <- length(twitterText)
twitterCnt <- sapply(twitterText, nchar)
twittweLongest <- max(twitterCnt)
dataFacts <- data.frame("Length" = twitterLng, "Longest_line" = twittweLongest)
row.names(dataFacts) <- c("Twitter")
dataFacts
```{r revProfanity_ASCII}
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity))) # Profanity filter
twitCorpus <- VCorpus(VectorSource(twitText_clean))
twitCorpus_clean <- tm_map(twitCorpus,removeNumbers) #removing numbers
twitCorpus_clean <- tm_map(twitCorpus_clean,content_transformer(tolower)) #converting to lower case letters
twitCorpus_clean <- tm_map(twitCorpus_clean,removePunctuation) #remving punctuation
twitCorpus_clean <- tm_map(twitCorpus_clean,stripWhitespace)
?tm_map
twit_tdm <- TermDocumentMatrix(twitCorpus_clean) #Tokenization
word_matrix <- sort(rowSums(as.matrix(twit_tdm)),decreasing=TRUE) #Order the the words
ma <- as.matrix(twit_tdm)
con <- file("en_US.twitter.txt", "r")
twitterText <- readLines(con, skipNul=T)
close(con)
set.seed(1345)
index <- rbinom(n = length(twitterText), size = 1, prob = 0.001)
twitterText <- twitterText[as.logical(index)]
twitterText <- iconv(twitterText, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
twitText_clean <- unlist(lapply(twitterText, function(i) removeWords(i, profanity))) # Profanity filter
twitCorpus <- VCorpus(VectorSource(twitText_clean))
twitCorpus_clean <- tm_map(twitCorpus,removeNumbers) #removing numbers
twitCorpus_clean <- tm_map(twitCorpus_clean,content_transformer(tolower)) #converting to lower case letters
twitCorpus_clean <- tm_map(twitCorpus_clean,removePunctuation) #remving punctuation
twitCorpus_clean <- tm_map(twitCorpus_clean,stripWhitespace)
```{r oneGrmFeq}
twit_tdm <- TermDocumentMatrix(twitCorpus_clean) #Tokenization
word_matrix <- sort(rowSums(as.matrix(twit_tdm)),decreasing=TRUE) #Order the the words
wordFreq <- data.frame(word = names(word_matrix),freq=word_matrix)
rownames(wordFreq) <- NULL
head(wordFreq,10) #Top 10 of frecuent word
plot_ly(x = ~wordFreq$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 2, colors=brewer.pal(8, "Dark2")) #Wordcloud
BigramTokenizer <-
function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE) # Get the bi-gram
twit_tdm2 <- TermDocumentMatrix(twitCorpus_clean, control = list(tokenize = BigramTokenizer)) #Tokenization
word_matrix2 <- sort(rowSums(as.matrix(twit_tdm2)),decreasing=TRUE)
wordFreq2 <- data.frame(word = names(word_matrix2),freq=word_matrix2)
rownames(wordFreq2) <- NULL
head(wordFreq2,10)
plot_ly(x = ~wordFreq2$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=500, min.freq = 2, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=200, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=100, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=80, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=60, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 6, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 5, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 8, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 10, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 12, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 15, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 20, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 18, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 19, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 20, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 34, colors=brewer.pal(8, "Dark2")) #Wordcloud
TrigramTokenizer <-
function(x)
unlist(lapply(ngrams(words(x), 3), paste, collapse = " "), use.names = FALSE) # Get the tri-gram
twit_tdm3 <- TermDocumentMatrix(twitCorpus_clean, control = list(tokenize = TrigramTokenizer))  #Tokenization
word_matrix3 <- sort(rowSums(as.matrix(twit_tdm3)),decreasing=TRUE)
word_matrix3 <- data.frame(word = names(word_matrix3),freq=word_matrix3)
rownames(word_matrix3) <- NULL
head(word_matrix3,10)
word_matrix3 <- sort(rowSums(as.matrix(twit_tdm3)),decreasing=TRUE)
wordFreq3 <- data.frame(word = names(word_matrix3),freq=word_matrix3)
rownames(wordFreq3) <- NULL
head(wordFreq3,10)
plot_ly(x = ~wordFreq3$freq, type = "histogram") # Distribution of the word freq
wordcloud(word_matrix3$word, word_matrix3$freq, max.words=200, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFre32$word, wordFreq3$freq, max.words=200, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=200, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=50, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=25, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=25, min.freq = 4, colors=brewer.pal(3, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=25, min.freq = 4, colors=brewer.pal(4, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=20, min.freq = 4, colors=brewer.pal(4, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=20, min.freq = 4, colors=brewer.pal(3, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "Set1")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "Set1")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "Accent")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "YlGn")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "PuOr")) #Wordcloud
twitterCon <- file("en_US.twitter.txt", "r")
newsCon <- file("en_US.news.txt", "r")
blogsCon <- file("en_US.blogs.txt", "r")
twitterText <- readLines(twitterCon, skipNul=T)
newsText <- readLines(newsCon, skipNul=T)
blogsText <- readLines(blogsCon, skipNul=T)
close(twitterCon)
close(newsCon)
close(blogsCon)
twitterLng <- length(twitterText)
twitterCnt <- sapply(twitterText, nchar)
twittweLongest <- max(twitterCnt)
newsLng <- length(newsText)
newsCnt <- sapply(newsText, nchar)
newsLongest <- max(newsCnt)
blogsLng <- length(blogsText)
blogsCnt <- sapply(blogsText, nchar)
blogsLongest <- max(blogsCnt)
dataFacts <- data.frame("Length" = c(twitterLng,newsLng,blogsLng), "Longest_line" = c(twitterLongest,newsLongest,blogsLongest))
twitterLongest <- max(twitterCnt)
dataFacts <- data.frame("Length" = c(twitterLng,newsLng,blogsLng), "Longest_line" = c(twitterLongest,newsLongest,blogsLongest))
row.names(dataFacts) <- c("Twitter","News","Blogs")
dataFacts
textList <- twitterText + newsText + blogsText
textList = twitterText + newsText + blogsText
textList = cbind(twitterText, newsText, blogsText)
textList <- cbind(twitterText, newsText)
textList <- cbind(twitterText, blogsText)
a<-c(1,2,3);b<-c(4,5,6)
cbind(a,b)
rbind(a,b)
abind(a,b)
c(a,b)
textList <- c(twitterText, newsText, blogsText)
set.seed(1345)
index <- rbinom(n = length(textList), size = 1, prob = 0.001)
sum(index)
textList1 <- textList[as.logical(index)]
textList <- textList[as.logical(index)]
textList <- iconv(textList, "latin1", "ASCII//TRANSLIT") # Remove foreing characters
profanity <- readLines("bad-words.txt")
text_clean <- unlist(lapply(textList, function(i) removeWords(i, profanity))) # Profanity filter
textCorpus <- VCorpus(VectorSource(text_clean))
textCorpus_clean <- tm_map(textCorpus,removeNumbers) #removing numbers
textCorpus_clean <- tm_map(textCorpus_clean,content_transformer(tolower)) #converting to lower case letters
textCorpus_clean <- tm_map(textCorpus_clean,removePunctuation) #remving punctuation
textCorpus_clean <- tm_map(textCorpus_clean,stripWhitespace)
text_tdm <- TermDocumentMatrix(textCorpus_clean) #Tokenization
word_matrix <- sort(rowSums(as.matrix(text_tdm)),decreasing=TRUE) #Order the the words
wordFreq <- data.frame(word = names(word_matrix),freq=word_matrix)
rownames(wordFreq) <- NULL
head(wordFreq,10) #Top 10 of frecuent word
plot_ly(x = ~wordFreq$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 24, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq$word, wordFreq$freq, max.words=200, min.freq = 30, colors=brewer.pal(8, "Dark2")) #Wordcloud
BigramTokenizer <-
function(x)
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE) # Get the bi-gram
text_tdm2 <- TermDocumentMatrix(textCorpus_clean, control = list(tokenize = BigramTokenizer)) #Tokenization
word_matrix2 <- sort(rowSums(as.matrix(text_tdm2)),decreasing=TRUE)
wordFreq2 <- data.frame(word = names(word_matrix2),freq=word_matrix2)
rownames(wordFreq2) <- NULL
head(wordFreq2,10)
plot_ly(x = ~wordFreq2$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq2$word, wordFreq2$freq, max.words=50, min.freq = 20, colors=brewer.pal(8, "Dark2")) #Wordcloud
TrigramTokenizer <-
function(x)
unlist(lapply(ngrams(words(x), 3), paste, collapse = " "), use.names = FALSE) # Get the tri-gram
text_tdm3 <- TermDocumentMatrix(textCorpus_clean, control = list(tokenize = TrigramTokenizer))  #Tokenization
word_matrix3 <- sort(rowSums(as.matrix(text_tdm3)),decreasing=TRUE)
wordFreq3 <- data.frame(word = names(word_matrix3),freq=word_matrix3)
rownames(wordFreq3) <- NULL
head(wordFreq3,10)
plot_ly(x = ~wordFreq3$freq, type = "histogram") # Distribution of the word freq
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=20, min.freq = 4, colors=brewer.pal(3, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(3, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
wordcloud(wordFreq3$word, wordFreq3$freq, max.words=15, min.freq = 4, colors=brewer.pal(8, "Dark2")) #Wordcloud
if (!require("devtools")) install.packages("devtools")
devtools::install_github("mkuhn/dict")
shiny::runApp('~/Coursera/Data Science/Data Science Capstone/NLP_Word_Predictor')
